{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fea095d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 02:23:12.697396: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-07 02:23:12.697414: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12307efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fall: TESTING_ML_v58.txt\n",
      "Fall: TESTING_ML_v55.txt\n",
      "Fall: TESTING_ML_v49.txt\n",
      "Fall: TESTING_ML_v9.txt\n",
      "Fall: TESTING_ML_v19.txt\n",
      "Fall: TESTING_ML_v29.txt\n",
      "Fall: TESTING_ML_v57.txt\n",
      "Fall: TESTING_ML_v25.txt\n",
      "Fall: TESTING_ML_v50.txt\n",
      "Fall: TESTING_ML_v23.txt\n",
      "Fall: TESTING_ML_v30.txt\n",
      "Fall: TESTING_ML_v56.txt\n",
      "Fall: TESTING_ML_v53.txt\n",
      "Fall: TESTING_ML_v28.txt\n",
      "Fall: TESTING_ML_v40.txt\n",
      "Fall: TESTING_ML_v16.txt\n",
      "TESTING_ML_v20.txt -78 822 4.7132685049761385\n",
      "Fall: TESTING_ML_v21.txt\n",
      "Fall: TESTING_ML_v59.txt\n",
      "Fall: TESTING_ML_v8.txt\n",
      "Fall: TESTING_ML_v52.txt\n",
      "Fall: TESTING_ML_v15.txt\n",
      "Fall: TESTING_ML_v22.txt\n",
      "Fall: TESTING_ML_v51.txt\n",
      "Fall: TESTING_ML_v54.txt\n",
      "TESTING_ML_v10.txt -102 798 12.53990430585497\n",
      "Same floor Fall: TESTING_ML_BB_v89.txt\n",
      "Same floor Fall: TESTING_ML_BB_v69.txt\n",
      "Same floor Fall: TESTING_ML_BB_v97.txt\n",
      "TESTING_ML_BB_v84.txt -384 516 1.5242047106606122\n",
      "Same floor Fall: TESTING_ML_BB_v101.txt\n",
      "Same floor Fall: TESTING_ML_BB_v96.txt\n",
      "TESTING_ML_BB_v83.txt 16 916 12.494886954270536\n",
      "Same floor Fall: TESTING_ML_BB_v76.txt\n",
      "TESTING_ML_BB_v82.txt -15 885 12.112625644343177\n",
      "Same floor Fall: TESTING_ML_BB_v71.txt\n",
      "Same floor Fall: TESTING_ML_BB_v99.txt\n",
      "Same floor Fall: TESTING_ML_BB_v90.txt\n",
      "Same floor Fall: TESTING_ML_BB_v100.txt\n",
      "TESTING_ML_BB_v74.txt -20 880 17.711648709253467\n",
      "Same floor Fall: TESTING_ML_BB_v70.txt\n",
      "TESTING_ML_BB_v94.txt -18 882 14.647467357874534\n",
      "Same floor Fall: TESTING_ML_BB_v95.txt\n",
      "Same floor Fall: TESTING_ML_BB_v91.txt\n",
      "Same floor Fall: TESTING_ML_BB_v87.txt\n",
      "Same floor Fall: TESTING_ML_BB_v73.txt\n",
      "Same floor Fall: TESTING_ML_BB_v77.txt\n",
      "Same floor Fall: TESTING_ML_BB_v88.txt\n",
      "Same floor Fall: TESTING_ML_BB_v75.txt\n",
      "Same floor Fall: TESTING_ML_BB_v72.txt\n",
      "Same floor Fall: TESTING_ML_BB_v92.txt\n",
      "Same floor Fall: TESTING_ML_BB_v93.txt\n",
      "Same floor Fall: TESTING_ML_BB_v78.txt\n",
      "Same floor Fall: TESTING_ML_BB_v98.txt\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "file_cnt = 0\n",
    "for dirpath, dirnames, filenames in os.walk(\"./Fall Data (New)/\"):\n",
    "    for filename in [f for f in filenames if f.endswith(\".txt\")]:\n",
    "        df = pd.read_csv(os.path.join(dirpath, filename),header=None)\n",
    "        fall_time = df[df[1].isna()]\n",
    "        df = df[df[1].notna()]\n",
    "        ax = np.array(df[1])\n",
    "        ay = np.array(df[2])\n",
    "        az = np.array(df[3])\n",
    "        gx = np.array(df[4])\n",
    "        gy = np.array(df[5])\n",
    "        gz = np.array(df[6])\n",
    "        time = np.array(df[0])\n",
    "        a = np.sqrt(ax**2 + ay**2 + az**2)\n",
    "        if filename[0] == \"A\":\n",
    "            # ADL file\n",
    "            file_cnt += 1\n",
    "            for i in range(a.shape[0]):\n",
    "                if a[i] >= 1.6:\n",
    "                    st = i - 450\n",
    "                    ed =  i + 450\n",
    "                    if st < 0 or ed >= a.shape[0]:\n",
    "                        continue\n",
    "\n",
    "                    tmp = np.array(list(zip(ax[st:ed],ay[st:ed],az[st:ed],gx[st:ed],gy[st:ed],gz[st:ed])))\n",
    "\n",
    "\n",
    "                    x.append(tmp)\n",
    "                    y.append(1)\n",
    "        elif filename[11] == \"B\":\n",
    "            i = np.argmax(a)\n",
    "            st = i - 450\n",
    "            ed =  i + 450\n",
    "            if st < 0 or ed >= a.shape[0] or a[i] < 1.6:\n",
    "                print(filename,st,ed,a[i])\n",
    "                continue\n",
    "            file_cnt += 1\n",
    "            tmp = np.array(list(zip(ax[st:ed],ay[st:ed],az[st:ed],gx[st:ed],gy[st:ed],gz[st:ed])))\n",
    "            x.append(tmp)\n",
    "            y.append(2)\n",
    "            print(\"Same floor Fall:\",filename)\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            # Fall Data\n",
    "            i = np.argmax(a)\n",
    "            st = i - 450\n",
    "            ed =  i + 450\n",
    "            if st < 0 or ed >= a.shape[0] or a[i] < 1.6:\n",
    "                print(filename,st,ed,a[i])\n",
    "                continue\n",
    "            file_cnt += 1\n",
    "            print(\"Fall:\",filename)\n",
    "            tmp = np.array(list(zip(ax[st:ed],ay[st:ed],az[st:ed],gx[st:ed],gy[st:ed],gz[st:ed])))\n",
    "            x.append(tmp)\n",
    "            y.append(0)\n",
    "print(file_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ddfedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 24, 1: 9446, 2: 23})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt =  Counter(y)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1be97f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9493, 900, 6, 1) (9493,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(x)\n",
    "Y = np.array(y)\n",
    "X = X.reshape(-1,900,6,1)\n",
    "# X_flat = X.reshape(-1,5400)\n",
    "print(X.shape,Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1927d6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9493, 900, 6, 1) (9493,) (9493, 5400)\n"
     ]
    }
   ],
   "source": [
    "orig_shape = X.shape\n",
    "\n",
    "wX = X.reshape(-1,5400)\n",
    "print(X.shape,Y.shape,wX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b74b765c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "over = SMOTE(sampling_strategy='not majority')\n",
    "under = RandomUnderSampler(sampling_strategy='majority')\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "new_X, new_Y = pipeline.fit_resample(wX, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4158e734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28338, 900, 6, 1) (28338,)\n"
     ]
    }
   ],
   "source": [
    "new_X = new_X.reshape((-1, 900, 6, 1))\n",
    "print(new_X.shape,new_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6bd472c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 9446, 1: 9446, 2: 9446})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt =  Counter(new_Y)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "682ec29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "new_X_train, new_X_test, new_y_train, new_y_test = train_test_split(new_X, new_Y, test_size=0.2, random_state=32)\n",
    "new_y_train_cat = keras.utils.to_categorical(new_y_train)\n",
    "new_y_test_cat = keras.utils.to_categorical(new_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "419a7dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 171, 1, 7)         2107      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1197)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 3594      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,701\n",
      "Trainable params: 5,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 02:31:14.809012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-07 02:31:14.809354: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-07 02:31:14.809403: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-07 02:31:14.809448: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-07 02:31:14.809492: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-07 02:31:14.809535: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-07 02:31:14.809579: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-07 02:31:14.809622: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-07 02:31:14.809666: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-09-07 02:31:14.809673: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-07 02:31:14.809885: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "model = Sequential()\n",
    "# 100%\n",
    "# model.add(Conv2D(20, kernel_size=(50,6), activation='relu', input_shape=(900,6,1),strides=5)) \n",
    "model.add(Conv2D(7, kernel_size=(50,6), activation='relu', input_shape=(900,6,1),strides=5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "adam = tf.keras.optimizers.Adam(learning_rate=0.001,)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "275bce21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 02:31:25.988266: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 367243200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 12/133 [=>............................] - ETA: 1s - loss: 0.6910 - accuracy: 0.7572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-07 02:31:26.415111: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29754000 exceeds 10% of free system memory.\n",
      "2022-09-07 02:31:26.430691: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29754000 exceeds 10% of free system memory.\n",
      "2022-09-07 02:31:26.448004: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29754000 exceeds 10% of free system memory.\n",
      "2022-09-07 02:31:26.464247: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29754000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 2s 14ms/step - loss: 0.0732 - accuracy: 0.9771 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 8.5237e-04 - accuracy: 1.0000 - val_loss: 4.9435e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 3.7492e-04 - accuracy: 1.0000 - val_loss: 2.6004e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 2.1203e-04 - accuracy: 1.0000 - val_loss: 1.5715e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 1.3659e-04 - accuracy: 1.0000 - val_loss: 1.0651e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 9.5156e-05 - accuracy: 1.0000 - val_loss: 7.7112e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 7.0414e-05 - accuracy: 1.0000 - val_loss: 5.7359e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 5.3929e-05 - accuracy: 1.0000 - val_loss: 4.4762e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 4.2608e-05 - accuracy: 1.0000 - val_loss: 3.5607e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 3.4400e-05 - accuracy: 1.0000 - val_loss: 2.9166e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 2.8340e-05 - accuracy: 1.0000 - val_loss: 2.4071e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 2.3693e-05 - accuracy: 1.0000 - val_loss: 2.0224e-05 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 2.0039e-05 - accuracy: 1.0000 - val_loss: 1.7174e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 1.7106e-05 - accuracy: 1.0000 - val_loss: 1.4745e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 1.4745e-05 - accuracy: 1.0000 - val_loss: 1.2770e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "133/133 [==============================] - 2s 12ms/step - loss: 1.2807e-05 - accuracy: 1.0000 - val_loss: 1.1088e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 1.1212e-05 - accuracy: 1.0000 - val_loss: 9.6946e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 9.8556e-06 - accuracy: 1.0000 - val_loss: 8.5396e-06 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 8.7196e-06 - accuracy: 1.0000 - val_loss: 7.5740e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "133/133 [==============================] - 2s 13ms/step - loss: 7.7448e-06 - accuracy: 1.0000 - val_loss: 6.7259e-06 - val_accuracy: 1.0000\n",
      "45/45 [==============================] - 0s 3ms/step - loss: 6.6538e-06 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.fit(new_X_train, new_y_train_cat, validation_split=0.25, epochs=20,batch_size=128)\n",
    "results = model.evaluate(new_X_test, new_y_test_cat, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "999a2ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[  24    0    0]\n",
      " [   0 9446    0]\n",
      " [   0    0   23]]\n",
      "Accuracy:100.0%\n",
      "Sensitivity:100.0%\n",
      "Specificity:100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=3372)\n",
    "#print(X_test.shape)\n",
    "predictions = model.predict(X, batch_size=128, verbose=0)\n",
    "classes_x=(np.argmax(predictions,axis=1))\n",
    "#print(predictions)\n",
    "true_classes = Y\n",
    "\n",
    "# y_test_flat = np.argmax(y_test, axis=-1)\n",
    "c = confusion_matrix(Y, classes_x)\n",
    "print('Confusion matrix:\\n', c)\n",
    "# print('Accuracy', )\n",
    "print('Accuracy:{}%'.format((c[0, 0] + c[1, 1]) * 100 / (c[0, 1] + c[0, 0] + c[1, 1] + c[1, 0])))\n",
    "print('Sensitivity:{}%'.format(c[0, 0]*100 / (c[0, 1] + c[0, 0])))\n",
    "print('Specificity:{}%'.format(c[1, 1]*100 / (c[1, 1] + c[1, 0])))\n",
    "# print('sensitivity', c[0, 0] / (c[0, 1] + c[0, 0]))\n",
    "# print('specificity', c[1, 1] / (c[1, 1] + c[1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8de1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894050bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
